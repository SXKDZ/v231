---
abstract: Nowadays, graph neural networks (GNN) are the primary machinery to tackle
  (semi)-supervised graph classification tasks. The aim here is to predict classes
  for unlabeled graphs, given a collection of graphs with known labels. However, in
  many real-world applications the available information on graph classes may be distorted
  either due to incorrect labelling process (e.g., as in biochemistry and bioinformatics)
  or may be subject to targeted attacks (e.g., as in network-based customer attrition
  analytics). Over the past few years, the increasing number of studies has indicated
  that GNNs are prone both to noisy node and noisy graph labels, and while this problem
  has received noticeable attention for node classification tasks, vulnerability of
  GNNs for graph classification with perturbed graph labels still remains in its nascence.
  We hypothesise that this challenge can be addressed  by the universal principle
  {\it United We Stand, Divided We Fall}. In particular, most GNNs view each graph
  as a standalone entity and, as a result, are limited in their abilities to account
  for complex interdependencies among the graphs. Inspired by the recent studies on
  molecular graph learning, we propose a new robust knowledge representation called
  {\it Networks to Graph} (N2G). The key N2G idea is to construct a new abstraction
  where each graph in the collection is now represented by a node, while an edge then
  reflects some sort of similarity among the graphs. As a result, the graph classification
  task can be then naturally reformulated as a node classification problem. We show
  that the proposed N2G representation approach does not only improve classification
  performance both in binary and multi-class scenarios but also substantially enhances
  robustness against noisy labels in the training data, leading to relative robustness
  gains up to 11.7\% on social network benchmarks and up to 25.8\% on bioinformatics
  graph benchmarks under 10\% of graph label corruption rate.
openreview: K5g021Ex14
section: Poster Presentations
title: 'United We Stand, Divided We Fall: Networks to Graph (N2G) Abstraction for
  Robust Graph Classification Under Graph Label Corruption'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhen24a
month: 0
tex_title: 'United We Stand, Divided We Fall: Networks to Graph (N2G) Abstraction
  for Robust Graph Classification Under Graph Label Corruption'
firstpage: '30:1'
lastpage: '30:19'
page: 30:1-30:19
order: 30
cycles: false
bibtex_author: Zhen, Zhiwei and Chen, Yuzhou and Kantarcioglu, Murat and Jee, Kangkook
  and Gel, Yulia
author:
- given: Zhiwei
  family: Zhen
- given: Yuzhou
  family: Chen
- given: Murat
  family: Kantarcioglu
- given: Kangkook
  family: Jee
- given: Yulia
  family: Gel
date: 2024-04-17
address:
container-title: Proceedings of the Second Learning on Graphs Conference
volume: '231'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 17
pdf: https://proceedings.mlr.press/v231/zhen24a/zhen24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
