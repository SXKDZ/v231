---
abstract: 'The Strong Lottery Ticket Hypothesis (SLTH) demonstrates the existence
  of high-performing subnetworks within a randomly initialized model, discoverable
  through pruning a convolutional neural network (CNN) without any weight training.
  A recent study, called Untrained GNNs Tickets (UGT), expanded SLTH from CNNs to
  shallow graph neural networks (GNNs). However, discrepancies persist when comparing
  baseline models with learned dense weights. Additionally, there remains an unexplored
  area in applying SLTH to deeper GNNs, which, despite delivering improved accuracy
  with additional layers, suffer from excessive memory requirements. To address these
  challenges, this work utilizes Multicoated Supermasks (M-Sup), a scalar pruning
  mask method, and implements it in GNNs by proposing a strategy for setting its pruning
  thresholds adaptively. In the context of deep GNNs, this research uncovers the existence
  of untrained recurrent networks, which exhibit performance on par with their trained
  feed-forward counterparts. This paper also introduces the Multi-Stage Folding and
  Unshared Masks methods to expand the search space in terms of both architecture
  and parameters. Through the evaluation of various datasets, including the Open Graph
  Benchmark (OGB), this work establishes a triple-win scenario for SLTH-based GNNs:
  by achieving high sparsity, competitive performance, and high memory efficiency
  with up to 98.7\% reduction, it demonstrates suitability for energy-efficient graph
  processing.'
openreview: oLrNolMbO8
section: Poster Presentations
title: Multicoated and Folded Graph Neural Networks With Strong Lottery Tickets
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yan24a
month: 0
tex_title: Multicoated and Folded Graph Neural Networks With Strong Lottery Tickets
firstpage: '11:1'
lastpage: '11:18'
page: 11:1-11:18
order: 11
cycles: false
bibtex_author: Yan, Jiale and Ito, Hiroaki and Garc\'ia-Arias, \'Angel L\'opez and
  Okoshi, Yasuyuki and Otsuka, Hikari and Kawamura, Kazushi and Chu, Thiem Van and
  Motomura, Masato
author:
- given: Jiale
  family: Yan
- given: Hiroaki
  family: Ito
- given: Ángel López
  family: García-Arias
- given: Yasuyuki
  family: Okoshi
- given: Hikari
  family: Otsuka
- given: Kazushi
  family: Kawamura
- given: Thiem Van
  family: Chu
- given: Masato
  family: Motomura
date: 2024-04-17
address:
container-title: Proceedings of the Second Learning on Graphs Conference
volume: '231'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 17
pdf: https://proceedings.mlr.press/v231/yan24a/yan24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
